{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Local imports\n",
    "import utils\n",
    "import data_handler\n",
    "from data_handler import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options/ Hyperparameters required to train and test the model\n",
    "opts = EasyDict()\n",
    "\n",
    "opts.n_epochs = 1000\n",
    "opts.batch_size = 32\n",
    "opts.learning_rate = 0.0001\n",
    "opts.lr_decay = 0.99\n",
    "opts.hidden_layer_size = 100\n",
    "opts.model_name = \"simple_rnn\"\n",
    "opts.checkpoints_dir = \"./checkpoints/\"+opts.model_name \n",
    "\n",
    "TEST_SENTENCE = 'i love deep learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.create_dir_if_not_exists(opts.checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pairs, vocab_size, idx_dict = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the line pairs into 8:2, train and val split\n",
    "num_lines = len(line_pairs)\n",
    "num_train = int(0.8 * num_lines)\n",
    "train_pairs, val_pairs = line_pairs[:num_train], line_pairs[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = create_dict(train_pairs)\n",
    "val_dict = create_dict(val_pairs)\n",
    "\n",
    "# Study the structure of the created train_dict and val_dict variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyGRUCell, self).__init__()\n",
    "        #TODO: zero intit, weight return\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_z=nn.Linear(input_size + hidden_size , hidden_size)\n",
    "        self.weight_r=nn.Linear(input_size + hidden_size , hidden_size)\n",
    "        self.weight = nn.Linear(input_size + hidden_size , hidden_size)\n",
    "        #self.weight_z = torch.zeros(input_size + hidden_size , hidden_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.weight_z)\n",
    "        #self.weight_r = torch.zeros(input_size + hidden_size , hidden_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.weight_r)\n",
    "        #self.weight = torch.zeros(input_size + hidden_size , hidden_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.weight)\n",
    "        #bias\n",
    "        #self.bias_z = torch.zeros(1 , hidden_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.bias_z,)\n",
    "        #self.bias_r = torch.zeros(1 , hidden_size,requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.bias_r)\n",
    "        #self.bias = torch.zeros(1 , hidden_size,requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.bias)\n",
    "    \n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"Forward pass of the GRU computation for one time step.\n",
    "\n",
    "        Arguments\n",
    "            x: batch_size x input_size\n",
    "            h_prev: batch_size x hidden_size\n",
    "\n",
    "        Returns:\n",
    "            h_new: batch_size x hidden_size\n",
    "        \"\"\"\n",
    "        #print h_prev.shape , x.shape, \"thiiiiis\"\n",
    "        input_concatenated = torch.cat((h_prev , x), 1)\n",
    "        z = torch.sigmoid(self.weight_z(input_concatenated))\n",
    "        r = torch.sigmoid(self.weight_r(input_concatenated))\n",
    "        g = torch.tanh(self.weight(torch.cat(((r*h_prev),x),1)))\n",
    "        h_new = ((1-z)*h_prev)+ (z*g)\n",
    "\n",
    "        # ------------\n",
    "        # FILL THIS IN\n",
    "        # ------------\n",
    "        # z = ...\n",
    "        # r = ...\n",
    "        # g = ...\n",
    "        # h_new = ...\n",
    "        return h_new \n",
    "   # def parameters(self):\n",
    "       # return[self.weight_z,self.weight_r, self.weight]\n",
    "\n",
    "# Implement your Encoder RNN using instances of GRU Cell you just created.\n",
    "# You would need a character embedding layer for this.\n",
    "# Implement your Encoder RNN using instances of GRU Cell you just created.\n",
    "# You would need a character embedding layer for this.\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = torch.nn.GRU(self.vocab_size, self.hidden_size, batch_first=True, num_layers = 1, bidirectional = True)\n",
    "        #self.gru = torch.nn.GRU(self.vocab_size, self.hidden_size, bidirectional = True)\n",
    "    \n",
    "        # embedding layer\n",
    "        # GRU cell\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward pass of the encoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            inputs: Input token indexes across a batch for all time steps in the sequence. (batch_size x seq_len)\n",
    "\n",
    "        Returns:\n",
    "            annotations: The hidden states computed at each step of the input sequence. (batch_size x seq_len x hidden_size)\n",
    "            hidden: The final hidden state of the encoder, for each sequence in a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        batch_size, seq_len = inputs.size()\n",
    "        inp_onehot = torch.FloatTensor(batch_size, self.vocab_size, seq_len)\n",
    "        inp_onehot.zero_()\n",
    "        #print(inputs.size())\n",
    "        #print(inp_onehot.size())\n",
    "        #print(torch.unsqueeze(inputs,1).size())\n",
    "        embed=inp_onehot.scatter_(1, (torch.unsqueeze(inputs,1).type(torch.LongTensor)), 1)\n",
    "        embed_unstack = torch.unbind(embed,2)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        annotations = []\n",
    "        for i in range (seq_len):\n",
    "            #print i\n",
    "            #print embed_unstack[i].shape , hidden.shape\n",
    "            #print embed_unstack[i].size() , \"embed_unstack\"\n",
    "            embed_unstack_input = torch.Tensor(embed_unstack[i]).unsqueeze(1)\n",
    "            #print batch_size\n",
    "            #print self.hidden_size\n",
    "            #print hidden.size(),\"hidden_size\"\n",
    "            #print embed_unstack_input.size() , \"embed input size\"\n",
    "            _ , hidden = self.gru(embed_unstack_input, hidden)\n",
    "            annotations.append(hidden)\n",
    "        #print (annotations.size())\n",
    "            \n",
    "        # The encoded embeddings should be of size batch_size x seq_len x hidden_size\n",
    "        # Complete the forward pass \n",
    "        # ....\n",
    "        \n",
    "        return annotations, hidden\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        \"\"\"Creates a tensor of zeros to represent the initial hidden states\n",
    "        of a batch of sequences.\n",
    "\n",
    "        Arguments:\n",
    "            bs: The batch size for the initial hidden state.\n",
    "\n",
    "        Returns:\n",
    "            hidden: An initial hidden state of all zeros. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        return torch.zeros(2,bs, self.hidden_size)\n",
    "   # def parameters(self):\n",
    "       # return self.cell.parameters()\n",
    "\n",
    "# Implement your Decoder RNN using instances of GRU Cell you just created.\n",
    "# You would need a character embedding layer for this. \n",
    "# In addition you would also require an activation function applied to the output of the GRU Cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.weight = torch.zeros(hidden_size , vocab_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.weight)\n",
    "        #self.bias = torch.zeros(1 , vocab_size, requires_grad=True)\n",
    "        #torch.nn.init.xavier_uniform_(self.bias)\n",
    "        self.weight= nn.Linear(hidden_size,vocab_size)\n",
    "        self.gru = torch.nn.GRU(self.vocab_size, self.hidden_size, bidirectional = True,  batch_first=True, num_layers = 1)\n",
    "        \n",
    "        # define embedding layer\n",
    "        # define GRU cell\n",
    "        # define out\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"Forward pass of the decoder RNN.\n",
    "\n",
    "        Arguments:\n",
    "            x: Input token indexes across a batch for a single time step. (batch_size x 1)\n",
    "            h_prev: The hidden states from the previous step, across a batch. (batch_size x hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: Un-normalized scores for each token in the vocabulary, across a batch. (batch_size x vocab_size)\n",
    "            h_new: The new hidden states, across a batch. (batch_size x hidden_size)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        inp_onehot = torch.FloatTensor(batch_size, self.vocab_size)\n",
    "        inp_onehot.zero_()\n",
    "        #print(inp_onehot.size())\n",
    "        #print(\"x size\", x.size())\n",
    "        embed=inp_onehot.scatter_(1, x.type(torch.LongTensor), 1)\n",
    "        embed=torch.Tensor(embed).unsqueeze(1)\n",
    "        #print h_prev.size()\n",
    "        #print(\"embed size\" ,embed.size())\n",
    "        _,h_new = self.gru(embed,h_prev)\n",
    "        out = h_new[:][0][:]\n",
    "        out= out.squeeze(1)\n",
    "        #print out.size()\n",
    "        output = self.weight(out) ##check this!\n",
    "        # Implement the forward pass of this network\n",
    "        # ....\n",
    "        return output, h_new\n",
    "   # def parameters(self):\n",
    "    #    return self.cell.parameters(), [self.weight, self.bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "### Setup: Create Encoder, Decoder Objects ###\n",
    "##########################################################################\n",
    "encoder = Encoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size)\n",
    "decoder = Decoder(vocab_size=vocab_size, hidden_size=opts.hidden_layer_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts):\n",
    "    \"\"\"Runs the main training loop; evaluates the model on the val set every epoch.\n",
    "        * Prints training and val loss each epoch.\n",
    "        * Prints qualitative translation results each epoch using TEST_SENTENCE\n",
    "\n",
    "    Arguments:\n",
    "        train_dict: The training word pairs, organized by source and target lengths.\n",
    "        val_dict: The validation word pairs, organized by source and target lengths.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        opts: The input arguments for hyper-parameters and others.\n",
    "    \"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    params_enc=encoder.parameters()\n",
    "    params_dec=decoder.parameters()\n",
    "    #print(params.size())\n",
    "    #decoder_param1= decoder.parameters()\n",
    "    #print(encoder1.parameters().size())\n",
    "    optimizer = optim.Adam(list(params_enc)+list(params_dec), lr=opts.learning_rate) \n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoints_dir, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    key=(11, 16)\n",
    "    #print(train_dict[key])\n",
    "    train_dict2 = {key: train_dict[key]}\n",
    "    for epoch in range(opts.n_epochs ):\n",
    "\n",
    "            # decay the learning rate of the optimizer\n",
    "            # ....\n",
    "    #         optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "        optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "        epoch_losses = []\n",
    "        for key in train_dict:\n",
    "            #print (train_dict[key])\n",
    "            #print(key)\n",
    "            #print(train_dict2[key])\n",
    "\n",
    "            input_strings, target_strings = zip(*train_dict[key])\n",
    "\n",
    "            # Make your input tensor and the target tensors\n",
    "            # HINT : use the function string_to_index_list given in data_handler.py\n",
    "            # input_tensors = ....\n",
    "            # output_tensors = ....\n",
    "            input_tensors = [data_handler.string_to_index_list(string, char_to_index, end_token) for string in input_strings]\n",
    "            output_tensors = [data_handler.string_to_index_list(string, char_to_index, end_token) for string in target_strings]\n",
    "            input_tensors = torch.Tensor(input_tensors)\n",
    "            output_tensors = torch.Tensor(output_tensors)\n",
    "            num_tensors = len(input_tensors)\n",
    "            num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "            for i in range(num_batches):\n",
    "                #print (i)\n",
    "                start = i * opts.batch_size\n",
    "                end = start + opts.batch_size\n",
    "\n",
    "                # Define inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "                # inputs = ....\n",
    "                # outputs = ....\n",
    "                inputs = torch.Tensor(input_tensors[start:end])\n",
    "                outputs = torch.Tensor(output_tensors[start:end])\n",
    "                # The batch size may be different in each epoch\n",
    "                BS = inputs.size(0)\n",
    "\n",
    "                encoder_annotations, encoder_hidden = encoder.forward(inputs)\n",
    "\n",
    "                # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "                # decoder_hidden = ....\n",
    "                decoder_hidden = encoder_hidden\n",
    "                # Define the first decoder input. This would essentially be the start_token\n",
    "                # decoder_input = ....\n",
    "                decoder_input = torch.Tensor([start_token for i in range(BS)])\n",
    "                #print(\"decoder sized 1\",decoder_input.size())\n",
    "                decoder_input = decoder_input.unsqueeze(1)\n",
    "                #print(\"decoder sized\",decoder_input.size())\n",
    "                loss = 0.0\n",
    "\n",
    "                seq_len = outputs.size(1)  # Gets seq_len from BS x seq_len\n",
    "                for i in range(seq_len):\n",
    "                    #print (\"this\" , i)\n",
    "                    #print(decoder_hidden.size())\n",
    "                    decoder_output, decoder_hidden = decoder.forward(decoder_input, decoder_hidden)\n",
    "                    #print (decoder_output.size())\n",
    "                    current_target = outputs[:,i]\n",
    "                    #print(current_target)\n",
    "                            # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                            # loss += ....\n",
    "                    #print(criterion(decoder_output, current_target.type(torch.LongTensor)))\n",
    "                    loss += criterion(decoder_output, current_target.type(torch.LongTensor))\n",
    "                            # Find out the most probable character (ni) from the softmax distribution produced\n",
    "                            # ni = ....\n",
    "\n",
    "                    decoder_input = outputs[:,i].unsqueeze(1)\n",
    "\n",
    "                loss /= float(seq_len)\n",
    "                #print(loss, \"loss\")\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "                        # Compute gradients\n",
    "                loss.backward()\n",
    "\n",
    "                        # Update the parameters of the encoder and decoder\n",
    "                optimizer.step()\n",
    "\n",
    "        train_loss = np.mean(epoch_losses)\n",
    "        val_loss = evaluate(val_dict, encoder, decoder, idx_dict, criterion, opts)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            utils.store_checkpoints(encoder, decoder, idx_dict, opts)\n",
    "\n",
    "        gen_string = find_pig_latin(TEST_SENTENCE, encoder, decoder, idx_dict, opts)\n",
    "        #gen_string=\"hello\"\n",
    "        print(\"Epoch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch, train_loss, val_loss, gen_string))\n",
    "\n",
    "        loss_log.write('{} {} {}\\n'.format(epoch, train_loss, val_loss))\n",
    "        loss_log.flush()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        utils.store_loss_plots(train_losses, val_losses, opts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_dict, encoder, decoder, idx_dict, criterion, opts):\n",
    "    \"\"\"Evaluates the model on a held-out validation or test set. \n",
    "    This should be pretty straight-forward if you have figured out how to do the training correctly.\n",
    "    From then, it's just copy and paste.\n",
    "\n",
    "    Arguments:\n",
    "        data_dict: The validation/test word pairs, organized by source and target lengths.\n",
    "        encoder: An encoder model to produce annotations for each step of the input sequence.\n",
    "        decoder: A decoder model to generate output tokens.\n",
    "        idx_dict: Contains char-to-index and index-to-char mappings, and start & end token indexes.\n",
    "        criterion: Used to compute the CrossEntropyLoss for each decoder output.\n",
    "        opts: The command-line arguments.\n",
    "\n",
    "    Returns:\n",
    "        mean_loss: The average loss over all batches from data_dict.\n",
    "    \"\"\"\n",
    "\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for key in data_dict:\n",
    "\n",
    "        input_strings, target_strings = zip(*data_dict[key])\n",
    "        # Make your input tensor and the target tensors\n",
    "        # HINT : use the function string_to_index_list given in data_handler.py\n",
    "        # input_tensors = ....\n",
    "        # output_tensors = ....\n",
    "        input_tensors = [data_handler.string_to_index_list(string, char_to_index, end_token) for string in input_strings]\n",
    "        output_tensors = [data_handler.string_to_index_list(string, char_to_index, end_token) for string in target_strings]\n",
    "        input_tensors = torch.Tensor(input_tensors)\n",
    "        output_tensors = torch.Tensor(output_tensors)\n",
    "        num_tensors = len(input_tensors)\n",
    "        num_batches = int(np.ceil(num_tensors / float(opts.batch_size)))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "\n",
    "            start = i * opts.batch_size\n",
    "            end = start + opts.batch_size\n",
    "\n",
    "            # Define inputs and targets for THIS batch, beginning at index 'start' to 'end'\n",
    "            # inputs = ....\n",
    "            # outputs = ....\n",
    "            inputs = torch.Tensor(input_tensors[start:end])\n",
    "            outputs = torch.Tensor(output_tensors[start:end])\n",
    "            # The batch size may be different in each epoch\n",
    "            BS = inputs.size(0)\n",
    "\n",
    "            encoder_annotations, encoder_hidden = encoder.forward(inputs)\n",
    "            \n",
    "            # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "            # decoder_hidden = ....\n",
    "            decoder_hidden = encoder_hidden\n",
    "            # Define the first decoder input. This would essentially be the start_token\n",
    "            # decoder_input = ....\n",
    "            decoder_input = torch.Tensor([start_token for i in range(BS)])\n",
    "            #print(\"decoder sized 1\",decoder_input.size())\n",
    "            decoder_input = decoder_input.unsqueeze(1)\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            seq_len = outputs.size(1)  # Gets seq_len from BS x seq_len\n",
    "\n",
    "            for i in range(seq_len):\n",
    "                decoder_output, decoder_hidden= decoder.forward(decoder_input, decoder_hidden)\n",
    "\n",
    "                current_target = outputs[:,i]\n",
    "                #print decoder_output.size()\n",
    "                # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "                # loss += ....\n",
    "                loss += criterion(decoder_output, current_target.type(torch.LongTensor))\n",
    "                # Find out the most probable character (ni) from the softmax distribution produced\n",
    "                # ni = ....\n",
    "                \n",
    "                # Update decoder_input at the next time step to be this time-step's target \n",
    "                # decoder_input = ....\n",
    "                decoder_output=torch.softmax(decoder_output.float(),1)\n",
    "                _, indices = torch.max(decoder_output, 1)\n",
    "                #indices=torch.unsqueeze(indices,1)\n",
    "                #inp_onehot = torch.FloatTensor(BS, vocab_size)\n",
    "                #inp_onehot.zero_()\n",
    "                #print(inp_onehot.size())\n",
    "                #print(\"x size\", x.size())\n",
    "                #decoder_input=inp_onehot.scatter_(1, indices.type(torch.LongTensor), 1)\n",
    "                decoder_input = outputs[:,i].unsqueeze(1)\n",
    "                \n",
    "            loss /= float(seq_len)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pig_latin(sentence, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a sentence from English to Pig-Latin, by splitting the sentence into\n",
    "    words (whitespace-separated), running the encoder-decoder model to translate each\n",
    "    word independently, and then stitching the words back together with spaces between them.\n",
    "    \"\"\"\n",
    "    return ' '.join([translate(word, encoder, decoder, idx_dict, opts) for word in sentence.split()])\n",
    "\n",
    "\n",
    "def translate(input_string, encoder, decoder, idx_dict, opts):\n",
    "    \"\"\"Translates a given string from English to Pig-Latin.\n",
    "    Not much to do here as well. Follows basically the same structure as that of the function evaluate.\n",
    "    \"\"\"\n",
    "\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "    start_token = idx_dict['start_token']\n",
    "    end_token = idx_dict['end_token']\n",
    "\n",
    "    max_generated_chars = 20\n",
    "    gen_string = ''\n",
    "    #print input_string\n",
    "    # convert given string to an array of indexes\n",
    "    # HINT: use the function string_to_index_list provided in data_handler\n",
    "    # indexes = ....\n",
    "    indexes = data_handler.string_to_index_list(input_string, char_to_index, end_token)\n",
    "    #print(input_string)\n",
    "    indexes =(torch.Tensor(indexes))\n",
    "    indexes =indexes.unsqueeze(0)\n",
    "    #print(indexes.size(), \"index size\")\n",
    "    encoder_annotations, encoder_last_hidden = encoder.forward(torch.Tensor(indexes))\n",
    "    #print(torch.Tensor(encoder_last_hidden).size())\n",
    "    # The last hidden state of the encoder becomes the first hidden state of the decoder\n",
    "    # decoder_hidden = ....\n",
    "\n",
    "    # Define the first decoder input. This would essentially be the start_token\n",
    "    # decoder_input = ....\n",
    "    decoder_hidden = encoder_last_hidden\n",
    "            # Define the first decoder input. This would essentially be the start_token\n",
    "            # decoder_input = ....\n",
    "    #print (decoder_hidden.size(), \"dec size\")\n",
    "    decoder_input = torch.Tensor([start_token for i in range(1)])\n",
    "    \n",
    "    decoder_input=decoder_input.unsqueeze(1)\n",
    "    #print(decoder_input.size(), \"size\")\n",
    "            #print(\"decoder sized 1\",decoder_input.size())\n",
    "    for i in range(max_generated_chars):\n",
    "        decoder_output, decoder_hidden= decoder.forward(decoder_input, decoder_hidden)\n",
    "    \n",
    "        # Calculate the cross entropy between the decoder distribution and Ground truth (current_target)\n",
    "        # loss += ....\n",
    "        \n",
    "        # Find out the most probable character (ni) from the softmax distribution produced\n",
    "        # ni = ....\n",
    "        _, indices = torch.max(decoder_output, 1)\n",
    "        \n",
    "        indices=indices.unsqueeze(1)\n",
    "        #print(indices.size(), \"size2\")\n",
    "        #indices=torch.unsqueeze(indices,1)\n",
    "        inp_onehot = torch.FloatTensor(1, vocab_size)\n",
    "        inp_onehot.zero_()\n",
    "                #print(inp_onehot.size())\n",
    "        #print(\"x size\", x.size())\n",
    "        decoder_input=inp_onehot.scatter_(1, indices.type(torch.LongTensor), 1)\n",
    "        #print(indices[0][0].item())\n",
    "        ni = index_to_char[indices[0][0].item()]\n",
    "        if ni == end_token:\n",
    "            break\n",
    "        else:\n",
    "            gen_string += ni\n",
    "            \n",
    "            # update decoder_input at the next time step to be ni \n",
    "            # decoder_input = ....\n",
    "\n",
    "    return gen_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train loss: 3.172 | Val loss: 3.006 | Gen: eyyyyyyyyyyyyyyyyyyy eaaayyyyyyyyyyyyyyyy eaaayyyyyyyyyyyyyyyy eaaaaayyyyyyyyyyyyyy\n",
      "Epoch:   1 | Train loss: 2.843 | Val loss: 2.830 | Gen: iaEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOS iaaEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOS iaaEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOS iiaaEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOS\n",
      "Epoch:   2 | Train loss: 2.726 | Val loss: 2.614 | Gen: aayyyyyyyyyyyyyyyyyy eaaaayyyyyyyyyyyyyyy eaaaayyyyyyyyyyyyyyy eaaaaayyyyyyyyyyyyyy\n",
      "Epoch:   3 | Train loss: 2.472 | Val loss: 2.382 | Gen: ayyyyyyyyyyyyyyyyyyy ooyyyyyyyyyyyyyyyyyy ooyyyyyyyyyyyyyyyyyy oooyyyyyyyyyyyyyyyyy\n",
      "Epoch:   4 | Train loss: 2.335 | Val loss: 2.190 | Gen: ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy eiyyyyyyyyyyyyyyyyyy eiiiyyyyyyyyyyyyyyyy\n",
      "Epoch:   5 | Train loss: 2.185 | Val loss: 2.100 | Gen: ayyyyyyyyyyyyyyyyyyy enyyyyyyyyyyyyyyyyyy enyyyyyyyyyyyyyyyyyy eniiyyyyyyyyyyyyyyyy\n",
      "Epoch:   6 | Train loss: 2.075 | Val loss: 2.035 | Gen: ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy\n",
      "Epoch:   7 | Train loss: 2.028 | Val loss: 1.978 | Gen: ayyyyyyyyyyyyyyyyyyy olyyyyyyyyyyyyyyyyyy oyyyyyyyyyyyyyyyyyyy oiiyyyyyyyyyyyyyyyyy\n",
      "Epoch:   8 | Train loss: 1.968 | Val loss: 1.925 | Gen: ayyyyyyyyyyyyyyyyyyy oyyyyyyyyyyyyyyyyyyy oyyyyyyyyyyyyyyyyyyy oityyyyyyyyyyyyyyyyy\n",
      "Epoch:   9 | Train loss: 1.942 | Val loss: 1.880 | Gen: ayyyyyyyyyyyyyyyyyyy aiyyyyyyyyyyyyyyyyyy aiyyyyyyyyyyyyyyyyyy eiiiiyyyyyyyyyyyyyyy\n",
      "Epoch:  10 | Train loss: 1.880 | Val loss: 1.870 | Gen: ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy elbyyyyyyyyyyyyyyyyy\n",
      "Epoch:  11 | Train loss: 1.863 | Val loss: 1.842 | Gen: ayyyyyyyyyyyyyyyyyyy ooyyyyyyyyyyyyyyyyyy eiyyyyyyyyyyyyyyyyyy eiliiyyyyyyyyyyyyyyy\n",
      "Epoch:  12 | Train loss: 1.809 | Val loss: 1.831 | Gen: ayyyyyyyyyyyyyyyyyyy ayyyyyyyyyyyyyyyyyyy eryyyyyyyyyyyyyyyyyy eryyyyyyyyyyyyyyyyyy\n",
      "Epoch:  13 | Train loss: 1.782 | Val loss: 1.793 | Gen: ayyyyyyyyyyyyyyyyyyy oryyyyyyyyyyyyyyyyyy ertyyyyyyyyyyyyyyyyy iitiiiiyyyyyyyyyyyyy\n",
      "Epoch:  14 | Train loss: 1.721 | Val loss: 1.722 | Gen: ayyyyyyyyyyyyyyyyyyy abyyyyyyyyyyyyyyyyyy eryyyyyyyyyyyyyyyyyy erlyyyyyyyyyyyyyyyyy\n",
      "Epoch:  15 | Train loss: 1.721 | Val loss: 1.676 | Gen: ayyyyyyyyyyyyyyyyyyy obyyyyyyyyyyyyyyyyyy eryyyyyyyyyyyyyyyyyy erlyyyyyyyyyyyyyyyyy\n",
      "Epoch:  16 | Train loss: 1.645 | Val loss: 1.663 | Gen: iyyyyyyyyyyyyyyyyyyy ortyyyyyyyyyyyyyyyyy erttyyyyyyyyyyyyyyyy erntyyyyyyyyyyyyyyyy\n",
      "Epoch:  17 | Train loss: 1.585 | Val loss: 1.595 | Gen: iyyyyyyyyyyyyyyyyyyy oryyyyyyyyyyyyyyyyyy ertyyyyyyyyyyyyyyyyy ernyyyyyyyyyyyyyyyyy\n",
      "Epoch:  18 | Train loss: 1.547 | Val loss: 1.547 | Gen: iyyyyyyyyyyyyyyyyyyy ordyyyyyyyyyyyyyyyyy erttyyyyyyyyyyyyyyyy arnntyyyyyyyyyyyyyyy\n",
      "Epoch:  19 | Train loss: 1.481 | Val loss: 1.499 | Gen: iyyyyyyyyyyyyyyyyyyy orttyyyyyyyyyyyyyyyy erttyyyyyyyyyyyyyyyy ernttyyyyyyyyyyyyyyy\n",
      "Epoch:  20 | Train loss: 1.426 | Val loss: 1.465 | Gen: iyyyyyyyyyyyyyyyyyyy ordiyyyyyyyyyyyyyyyy ertyyyyyyyyyyyyyyyyy erliiyyyyyyyyyyyyyyy\n",
      "Exiting early from training.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_model(train_dict, val_dict, idx_dict, encoder, decoder, opts)\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting early from training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
