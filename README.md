# pig-latin-translator-attn
Pig Latin translator using an autoencoder with GRU cell, w and w/o attention weights, in PyTorch.

This was a course assignment for course 291-G (Deep Learning for sequences) at UCSD. The assignment was in two parts. The questions and the reports along with the code are included in the repo. Part 1 does not have attention mechanism, but the GRU cell is implemented. Part 2 has attention, but the GRU cell is PyTorch's cell.
